#!/usr/bin/env python3

"""
EQN RESTORATION BATCH - VERSION V4 (–û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–ê–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø)

–ü–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:

–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:
1. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ .eps –≤ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞—Ö
2. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–æ–≥–∏–∫–∏ –∑–∞–º–µ–Ω—ã –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤  
3. –¢–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
4. –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏–º–≤–æ–ª–æ–≤
5. –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—è—Ç—ã—Ö
"""

import sys
from pathlib import Path
import re
from datetime import datetime
import json

try:
    from docx import Document
except ImportError:
    print("–û—à–∏–±–∫–∞: –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ python-docx.")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx")
    sys.exit(1)

class PlaceholderRestorer:
    """–û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤"""

    def __init__(self):
        self.stats = {
            'placeholders_replaced': 0,
            'placeholders_found_in_translation': 0,
            'placeholders_found_in_original': 0,
            'damaged_placeholders_fixed': 0,
            'damaged_placeholders_details': []
        }

        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –í–°–ï–• –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö)
        self.pattern_all_placeholders = re.compile(
            r'(?:<<|<\s*<|<|^|\s)'           # –Ω–∞—á–∞–ª–æ 
            r'(Eqn\d+(?:\.eps)?)'             # –æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å (–≥—Ä—É–ø–ø–∞ 1)
            r'(?:>>>|>>|>\s*>|>|(?=\s)|(?=$)|(?=[,.]))'  # –∫–æ–Ω–µ—Ü
            r'(?:[,.>\s]*)?',                  # –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –ø–æ—Å–ª–µ
            re.IGNORECASE | re.MULTILINE
        )

    def extract_placeholders_list(self, doc_path):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –ø–æ—Ä—è–¥–∫–µ –ø–æ—è–≤–ª–µ–Ω–∏—è
        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        """
        placeholders = []

        try:
            document = Document(doc_path)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å {doc_path.name}: {e}")
            return []

        def extract_from_text(text):
            """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ç–æ—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
            if not text:
                return []

            # –ò—â–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
            found_placeholders = []

            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–µ
            correct_pattern = re.compile(r'<<Eqn\d+(?:\.eps)?>>(?:,)?', re.IGNORECASE)
            for match in correct_pattern.finditer(text):
                found_placeholders.append((match.start(), match.end(), match.group()))

            # –ó–∞—Ç–µ–º –∏—â–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ –≤ –º–µ—Å—Ç–∞—Ö, –≥–¥–µ –Ω–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö
            damaged_patterns = [
                r'(?<!<)Eqn\d+(?:\.eps)?>>(?:,)?',  # –±–µ–∑ <<
                r'<<Eqn\d+(?:\.eps)?(?!>>)',        # –±–µ–∑ >>  
                r'<\s+<Eqn\d+(?:\.eps)?>\s*>',    # —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
                r'<<Eqn\d+(?:\.eps)?>>>+(?:,)?',    # –ª–∏—à–Ω–∏–µ >
            ]

            for pattern in damaged_patterns:
                for match in re.finditer(pattern, text, re.IGNORECASE):
                    start, end = match.start(), match.end()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç—Å—è –ª–∏ —Å —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏
                    overlap = False
                    for existing_start, existing_end, _ in found_placeholders:
                        if not (end <= existing_start or start >= existing_end):
                            overlap = True
                            break

                    if not overlap:
                        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                        original = match.group()
                        eqn_match = re.search(r'Eqn(\d+)', original, re.IGNORECASE)
                        if eqn_match:
                            num = eqn_match.group(1)
                            has_eps = '.eps' in original.lower()
                            has_comma = original.endswith(',')

                            if has_eps:
                                fixed = f'<<Eqn{num}.eps>>'
                            else:
                                fixed = f'<<Eqn{num}>>'

                            if has_comma:
                                fixed = fixed[:-2] + ',>>'

                            found_placeholders.append((start, end, fixed))

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–∑–∏—Ü–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
            found_placeholders.sort(key=lambda x: x[0])
            return [placeholder for _, _, placeholder in found_placeholders]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞
        for para in document.paragraphs:
            placeholders.extend(extract_from_text(para.text))

        for table in document.tables:
            for row in table.rows:
                for cell in row.cells:
                    for para in cell.paragraphs:
                        placeholders.extend(extract_from_text(para.text))

        for section in document.sections:
            for para in section.header.paragraphs:
                placeholders.extend(extract_from_text(para.text))
            for para in section.footer.paragraphs:
                placeholders.extend(extract_from_text(para.text))

        return placeholders

    def process_document(self, doc_path, output_path=None, original_doc_path=None):
        """
        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        # –°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.stats = {
            'placeholders_replaced': 0,
            'placeholders_found_in_translation': 0,
            'placeholders_found_in_original': 0,
            'damaged_placeholders_fixed': 0,
            'damaged_placeholders_details': []
        }

        if output_path is None:
            output_path = doc_path.parent / f"{doc_path.stem}_fixed{doc_path.suffix}"

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        try:
            document = Document(doc_path)
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}"

        if not original_doc_path:
            return False, "–ù–µ —É–∫–∞–∑–∞–Ω –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç"

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        original_placeholders = self.extract_placeholders_list(original_doc_path)
        if not original_placeholders:
            return False, f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞"

        self.stats['placeholders_found_in_original'] = len(original_placeholders)
        print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ: {len(original_placeholders)}")

        # –°—á–µ—Ç—á–∏–∫ –¥–ª—è –∑–∞–º–µ–Ω—ã
        placeholder_index = 0

        def replace_placeholder(match):
            """–ó–∞–º–µ–Ω—è–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞"""
            nonlocal placeholder_index

            if placeholder_index < len(original_placeholders):
                replacement = original_placeholders[placeholder_index]
                placeholder_index += 1
                self.stats['placeholders_replaced'] += 1
                return replacement
            else:
                placeholder_index += 1
                return match.group(0)

        def process_text(text, location=""):
            """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å –∑–∞–º–µ–Ω–æ–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤"""
            if not text:
                return text

            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∑–∞–º–µ–Ω—ã
            # –ù–∞—Ö–æ–¥–∏–º –í–°–ï –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ) –∏ –∑–∞–º–µ–Ω—è–µ–º –∏—Ö

            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
            comprehensive_pattern = re.compile(
                r'(?:<<|<\s*<|(?<!\w))Eqn\d+(?:\.eps)?(?:>>|>\s*>|(?=\W)|$)(?:[,>\s]*)?',
                re.IGNORECASE
            )

            result_text = comprehensive_pattern.sub(replace_placeholder, text)
            return result_text

        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å
        placeholder_index = 0

        print("\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        for i, para in enumerate(document.paragraphs):
            if para.text and 'Eqn' in para.text:
                original_text = para.text
                new_text = process_text(para.text, f"–ü–∞—Ä–∞–≥—Ä–∞—Ñ {i+1}")
                if new_text != original_text:
                    para.text = new_text
                    print(f"  ‚úèÔ∏è –ü–∞—Ä–∞–≥—Ä–∞—Ñ {i+1}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü
        for t_idx, table in enumerate(document.tables):
            for r_idx, row in enumerate(table.rows):
                for c_idx, cell in enumerate(row.cells):
                    for p_idx, para in enumerate(cell.paragraphs):
                        if para.text and 'Eqn' in para.text:
                            original_text = para.text
                            new_text = process_text(para.text, f"–¢–∞–±–ª–∏—Ü–∞ {t_idx+1}")
                            if new_text != original_text:
                                para.text = new_text

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–æ–≤
        for s_idx, section in enumerate(document.sections):
            for para in section.header.paragraphs:
                if para.text and 'Eqn' in para.text:
                    para.text = process_text(para.text, f"–ó–∞–≥–æ–ª–æ–≤–æ–∫ {s_idx+1}")
            for para in section.footer.paragraphs:
                if para.text and 'Eqn' in para.text:
                    para.text = process_text(para.text, f"–ü–æ–¥–≤–∞–ª {s_idx+1}")

        self.stats['placeholders_found_in_translation'] = placeholder_index

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        try:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            document.save(output_path)

            message = f"–ó–∞–º–µ–Ω–µ–Ω–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤: {self.stats['placeholders_replaced']}/{self.stats['placeholders_found_in_translation']}; –î–æ—Å—Ç—É–ø–Ω–æ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ: {self.stats['placeholders_found_in_original']}"

            return True, message

        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}"

def process_single_file():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""

    print("\n" + "="*70)
    print(" EQN RESTORATION BATCH - VERSION V4")
    print(" –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–ê–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø")
    print("="*70)

    restorer = PlaceholderRestorer()

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    print("\n1. –ü—É—Ç—å –∫ –ü–ï–†–ï–í–ï–î–ï–ù–ù–û–ú–£ —Ñ–∞–π–ª—É:")
    file_path = input(" ‚Üí ").strip().strip('"\'')
    file_path = Path(file_path)

    if not file_path.exists():
        print(f"\n‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª  
    print("\n2. –ü—É—Ç—å –∫ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ú–£ —Ñ–∞–π–ª—É:")
    original_path = input(" ‚Üí ").strip().strip('"\'')
    original_path = Path(original_path)

    if not original_path.exists():
        print(f"\n‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {original_path}")
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    print("\nüîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    success, message = restorer.process_document(
        file_path,
        original_doc_path=original_path
    )

    if success:
        print(f"\n‚úÖ –£–°–ü–ï–®–ù–û!")
        print(f"üìä {message}")
        output_path = file_path.parent / f"{file_path.stem}_fixed{file_path.suffix}"
        print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç: {output_path}")
    else:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {message}")

if __name__ == "__main__":
    try:
        process_single_file()
    except KeyboardInterrupt:
        print("\n\n–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n\n–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
