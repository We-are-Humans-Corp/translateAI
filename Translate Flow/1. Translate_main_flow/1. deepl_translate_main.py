import deepl
import os
import sys
import time
import traceback
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import re  # –î–ª—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
from dotenv import load_dotenv

# === –î–û–ë–ê–í–ò–¢–¨ –ü–û–°–õ–ï –í–°–ï–• –ò–ú–ü–û–†–¢–û–í (–ø–µ—Ä–µ–¥ –ø—Ä–æ–≤–µ—Ä–∫–æ–π DEEPL_API_KEY) ===

import argparse


def parse_arguments():
    """–ü–∞—Ä—Å–∏—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
    parser = argparse.ArgumentParser(description='DeepL Document Translator')
    parser.add_argument('--input', type=str, help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É')
    parser.add_argument('--output', type=str, help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É')
    parser.add_argument('--source', type=str, default='RU', help='–ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫')
    parser.add_argument('--target', type=str, default='EN-US', help='–¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫')
    parser.add_argument('--no-interactive', action='store_true', help='–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –±–µ–∑ –∑–∞–ø—Ä–æ—Å–æ–≤')

    return parser.parse_args()


# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å –≥–ª–æ—Å—Å–∞—Ä–∏—è –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
try:
    from deepl_glossary_python import glossary_entries
except ImportError:
    print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π –∏–∑ deepl_glossary_python.py")
    print("–ü–µ—Ä–µ–≤–æ–¥ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è.")
    glossary_entries = None

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç python-docx ---
try:
    from docx import Document
    from docx.shared import Pt  # –î–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å–æ —Å—Ç–∏–ª—è–º–∏, –µ—Å–ª–∏ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è
    from docx.text.paragraph import Paragraph
    from docx.text.run import Run
except ImportError:
    print("–û—à–∏–±–∫–∞: –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ python-docx.")
    print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–µ: pip install python-docx")
    sys.exit(1)
# --- –ö–æ–Ω–µ—Ü –¥–æ–±–∞–≤–ª–µ–Ω–∏—è ---

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ .env —Ñ–∞–π–ª—É (—Ç–µ–ø–µ—Ä—å –Ω—É–∂–Ω–æ –ø–æ–¥–Ω—è—Ç—å—Å—è –Ω–∞ 3 Translate_politics —É—Ä–æ–≤–Ω—è –≤–≤–µ—Ä—Ö)
BASE_DIR = Path(__file__).resolve().parent.parent.parent
load_dotenv(BASE_DIR / '.env')

# --- Configuration ---
# –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
DEEPL_API_KEY = os.getenv('DEEPL_API_KEY', '')

SUPPORTED_EXTENSIONS = ['.docx', '.pdf']
TRANSLATION_SUFFIX = "_to_{target_lang_code}"
MAX_CONCURRENT_TRANSLATIONS = 1  # –í—Å–µ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
PAUSE_BETWEEN_REQUESTS = 2  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

LANGUAGE_OPTIONS = {
    "1": {"name": "–†—É—Å—Å–∫–∏–π -> –ê–Ω–≥–ª–∏–π—Å–∫–∏–π (US)", "source": "RU", "target": "EN-US"},
    "2": {"name": "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π -> –†—É—Å—Å–∫–∏–π", "source": "EN", "target": "RU"},
    "3 Translate_politics": {"name": "–ù–µ–º–µ—Ü–∫–∏–π -> –†—É—Å—Å–∫–∏–π", "source": "DE", "target": "RU"},
    # –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ —è–∑—ã–∫–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
}


# --- Helper Functions ---

def check_api_key_placeholder():
    """Checks if the API key is present in environment variables."""
    if not DEEPL_API_KEY:
        print("–û—à–∏–±–∫–∞: –ö–ª—é—á DeepL API –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –¥–æ–±–∞–≤—å—Ç–µ:")
        print("DEEPL_API_KEY=your_api_key_here")
        print("\n–ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è DEEPL_API_KEY")
        sys.exit(1)


def get_translation_direction():
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    print("\n–í—ã–±–µ—Ä–∏—Ç–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞:")
    for key, value in LANGUAGE_OPTIONS.items():
        print(f"  {key}: {value['name']}")

    while True:
        choice = input(f"–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä ({', '.join(LANGUAGE_OPTIONS.keys())}): ").strip()
        if choice in LANGUAGE_OPTIONS:
            selected_lang = LANGUAGE_OPTIONS[choice]
            print(f"–í—ã–±—Ä–∞–Ω–æ: {selected_lang['name']}")
            return selected_lang['source'], selected_lang['target']
        else:
            print("–û—à–∏–±–∫–∞: –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤.")


def initialize_translator(api_key):
    """Initializes the DeepL translator and checks usage."""
    print("\n–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ DeepL...")
    try:
        translator = deepl.Translator(api_key)
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤ DeepL API...")
        usage = translator.get_usage()

        # Character limit check
        char_count = usage.character.count
        char_limit = usage.character.limit
        limit_reached_char = False

        # –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –∑–∞—Ç—Ä–∞—Ç (‚Ç¨20.00 –∑–∞ 1 –º–∏–ª–ª–∏–æ–Ω —Å–∏–º–≤–æ–ª–æ–≤)
        PRICE_PER_MILLION = 20.00  # EUR

        if char_count is not None:
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–∞—Ç—Ä–∞—Ç—ã
            millions_used = char_count / 1_000_000
            total_cost = millions_used * PRICE_PER_MILLION

            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            count_str = f"{char_count:,}"
            cost_str = f"‚Ç¨{total_cost:.2f}"

            print(f"\n{'=' * 60}")
            print(f"üí∞ –ö–ê–õ–¨–ö–£–õ–Ø–¢–û–† –ó–ê–¢–†–ê–¢ DeepL API")
            print(f"{'=' * 60}")
            print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {count_str}")
            print(f"üí∂ –¢–∞—Ä–∏—Ñ: ‚Ç¨{PRICE_PER_MILLION:.2f} –∑–∞ 1 –º–∏–ª–ª–∏–æ–Ω —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"üí∏ –û–ë–©–ò–ï –ó–ê–¢–†–ê–¢–´: {cost_str}")
            print(f"{'=' * 60}")

            if char_limit is not None:
                limit_str = f"{char_limit:,}"
                remaining = max(0, char_limit - char_count)
                remaining_str = f"{remaining:,}"
                percentage_used = (char_count / char_limit) * 100

                print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:")
                print(f"  ‚Ä¢ –õ–∏–º–∏—Ç: {limit_str} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {count_str} ({percentage_used:.2f}%)")
                print(f"  ‚Ä¢ –û—Å—Ç–∞–ª–æ—Å—å: {remaining_str}")

                if char_count >= char_limit:
                    limit_reached_char = True
                    print("  ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –õ–∏–º–∏—Ç —Å–∏–º–≤–æ–ª–æ–≤ –∏—Å—á–µ—Ä–ø–∞–Ω!")
            else:
                print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:")
                print(f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {count_str} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"  ‚Ä¢ –õ–∏–º–∏—Ç: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        else:
            print("  –õ–∏–º–∏—Ç —Å–∏–º–≤–æ–ª–æ–≤: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è –∏–ª–∏ –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ.")

        # Document limit check
        doc_count = None
        doc_limit = None
        limit_reached_doc = False
        if hasattr(usage, 'document') and usage.document and usage.document.valid:
            doc_count = usage.document.count
            doc_limit = usage.document.limit
            if doc_limit is not None:
                count_str = f"{doc_count:,}" if doc_count is not None else "N/A"
                limit_str = f"{doc_limit:,}"
                remaining_str = ""
                if doc_count is not None:
                    remaining_str = f"(–û—Å—Ç–∞–ª–æ—Å—å: {max(0, doc_limit - doc_count):,})"
                    if doc_count is not None and doc_limit is not None and doc_count >= doc_limit: limit_reached_doc = True
                print(f"  –õ–∏–º–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {count_str} –∏–∑ {limit_str} {remaining_str}")
                if limit_reached_doc: print("–í–Ω–∏–º–∞–Ω–∏–µ: –õ–∏–º–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∏—Å—á–µ—Ä–ø–∞–Ω –∏–ª–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç!")
            elif doc_count is not None:
                print(f"  –õ–∏–º–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {doc_count:,} (–õ–∏–º–∏—Ç –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ –∏–∑–≤–µ—Å—Ç–µ–Ω)")
            else:
                print("  –õ–∏–º–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è –∏–ª–∏ –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ –¥–ª—è —ç—Ç–æ–≥–æ –ø–ª–∞–Ω–∞.")
        else:
            print("  –õ–∏–º–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: –ù–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ –∏–ª–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ API (–≤–æ–∑–º–æ–∂–Ω–æ, DeepL API Free?)")

        # Final check if any limit is exceeded
        if limit_reached_char or limit_reached_doc:
            error_msg = "–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è DeepL API."
            if limit_reached_char: error_msg = "–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å–∏–º–≤–æ–ª–æ–≤ DeepL API."
            if limit_reached_doc: error_msg = "–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ DeepL API."
            print(f"\n–û—à–∏–±–∫–∞: {error_msg}")
            print("–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
            sys.exit(1)
        else:
            print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DeepL —É—Å–ø–µ—à–Ω–∞. –õ–∏–º–∏—Ç—ã –≤ –Ω–æ—Ä–º–µ.")
        return translator

    except deepl.AuthorizationException:
        print("\n–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ DeepL: –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á.")
        sys.exit(1)
    except Exception as e:
        print(f"\n–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DeepL: {e}")
        print(traceback.format_exc())
        sys.exit(1)


def get_or_create_glossary(translator, source_lang, target_lang):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π."""
    # –ï—Å–ª–∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π –Ω–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
    if glossary_entries is None:
        return None

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º
    if source_lang != "RU" or target_lang not in ["EN-US", "EN-GB", "EN"]:
        print("–ì–ª–æ—Å—Å–∞—Ä–∏–π –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.")
        return None

    glossary_name = f"Universal Scientific Terms RU-EN v1"

    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π
        print("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≥–ª–æ—Å—Å–∞—Ä–∏–µ–≤...")
        glossaries = translator.list_glossaries()

        for glossary in glossaries:
            if glossary.name == glossary_name and glossary.source_lang == "RU" and glossary.target_lang == "EN":
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –≥–ª–æ—Å—Å–∞—Ä–∏–π: {glossary.name} (ID: {glossary.glossary_id})")
                print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {glossary.entry_count}")
                return glossary

        # –ï—Å–ª–∏ –≥–ª–æ—Å—Å–∞—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
        print("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –≥–ª–æ—Å—Å–∞—Ä–∏—è –Ω–∞—É—á–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤...")
        glossary = translator.create_glossary(
            name=glossary_name,
            source_lang="RU",
            target_lang="EN",
            entries=glossary_entries
        )
        print(f"‚úÖ –ì–ª–æ—Å—Å–∞—Ä–∏–π —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {glossary.name} (ID: {glossary.glossary_id})")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(glossary_entries)}")
        return glossary

    except deepl.DeepLException as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å/–ø–æ–ª—É—á–∏—Ç—å –≥–ª–æ—Å—Å–∞—Ä–∏–π: {e}")
        print("   –ü–µ—Ä–µ–≤–æ–¥ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è.")
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º: {e}")
        print("   –ü–µ—Ä–µ–≤–æ–¥ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è.")
        return None


def find_files_to_translate(source_root_path):
    """Recursively finds files with supported extensions, excluding temporary files."""
    print("\n–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞...")
    files_found = []
    for extension in SUPPORTED_EXTENSIONS:
        extension_pattern = "".join([f"[{c.lower()}{c.upper()}]" for c in extension[1:]])
        pattern = f"*.{extension_pattern}"
        # print(f"–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ —Å —à–∞–±–ª–æ–Ω–æ–º: {pattern} –≤ {source_root_path}") # Debug log
        files_found.extend(list(source_root_path.rglob(pattern)))

    processed_paths = set()
    files_to_process = []
    for f in files_found:
        try:
            resolved_f = f.resolve()
            if resolved_f.is_file() and not resolved_f.name.startswith('~$') and resolved_f not in processed_paths:
                files_to_process.append(resolved_f)
                processed_paths.add(resolved_f)
        except Exception as e:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—É—Ç—å —Ñ–∞–π–ª–∞ '{f}': {e}. –ü—Ä–æ–ø—É—Å–∫.")

    files_to_process.sort()
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(files_to_process)} —Ñ–∞–π–ª–æ–≤ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ {SUPPORTED_EXTENSIONS} (–∏—Å–∫–ª—é—á–∞—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã).")
    return files_to_process


def estimate_translation_cost(file_paths):
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞ —Ñ–∞–π–ª–æ–≤"""
    total_chars = 0
    file_estimates = []

    print("\nüìä –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–∞...")
    print("-" * 60)

    for file_path in file_paths[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤
        try:
            # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~2000 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è DOCX, ~3000 –¥–ª—è PDF
            file_size = file_path.stat().st_size

            if file_path.suffix.lower() == '.docx':
                # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ * 0.5 (–æ—á–µ–Ω—å –≥—Ä—É–±–æ)
                estimated_chars = int(file_size * 0.5)
            elif file_path.suffix.lower() == '.pdf':
                # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ * 0.3 Translate_politics (–æ—á–µ–Ω—å –≥—Ä—É–±–æ)
                estimated_chars = int(file_size * 0.3)
            else:
                estimated_chars = int(file_size * 0.4)

            total_chars += estimated_chars
            file_estimates.append((file_path.name, estimated_chars))

        except Exception:
            continue

    # –≠–∫—Å—Ç—Ä–∞–ø–æ–ª–∏—Ä—É–µ–º –Ω–∞ –≤—Å–µ —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –∏—Ö –±–æ–ª—å—à–µ 10
    if len(file_paths) > 10:
        avg_chars = total_chars / min(10, len(file_paths))
        total_chars = int(avg_chars * len(file_paths))
        print(f"–ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö 10 —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(file_paths)}...")

    # –†–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    PRICE_PER_MILLION = 20.00  # EUR
    millions = total_chars / 1_000_000
    estimated_cost = millions * PRICE_PER_MILLION

    print(f"\nüí∞ –û–¶–ï–ù–ö–ê –°–¢–û–ò–ú–û–°–¢–ò:")
    print(f"  ‚Ä¢ –§–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞: {len(file_paths)}")
    print(f"  ‚Ä¢ –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤: {total_chars:,}")
    print(f"  ‚Ä¢ –¢–∞—Ä–∏—Ñ: ‚Ç¨{PRICE_PER_MILLION:.2f} –∑–∞ 1 –º–ª–Ω —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"  ‚Ä¢ –ü–†–ò–ú–ï–†–ù–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨: ‚Ç¨{estimated_cost:.2f}")
    print("-" * 60)
    print("‚ö†Ô∏è  –≠—Ç–æ –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞. –†–µ–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç")
    print("   —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")

    return total_chars, estimated_cost


def clean_translated_docx(docx_path):
    """
    –û—Ç–∫—Ä—ã–≤–∞–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π DOCX –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
    –∫ –≤–∏–¥—É <<EqnXXX.eps>>. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ª—É—á–∞–∏ —Å –ª–∏—à–Ω–µ–π —Ç–æ—á–∫–æ–π,
    –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ >>, –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º .eps.
    –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ñ–∞–π–ª. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ/–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π, False –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    try:
        if not docx_path.is_file():
            print(f"  -> –û–®–ò–ë–ö–ê –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω {docx_path}")
            return False

        document = Document(docx_path)
        changes_made = 0  # –°—á–µ—Ç—á–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

        # –£–õ–£–ß–®–ï–ù–ù–û–ï –†–ï–ì–£–õ–Ø–†–ù–û–ï –í–´–†–ê–ñ–ï–ù–ò–ï v3:
        pattern = re.compile(
            r'(<<Eqn(\d+))'  # –ì—Ä—É–ø–ø–∞ 1: <<Eqn<—Ü–∏—Ñ—Ä—ã>, –ì—Ä—É–ø–ø–∞ 2: —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
            r'(?!'  # –ù–∞—á–∞–ª–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–ø–µ—Ä–µ–¥ (—É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –î–ê–õ–¨–®–ï –ù–ï...)
            r'\.eps>>'  # ...—Ä–æ–≤–Ω–æ ".eps>>"
            r'([,\s]|$)'  # ...–∑–∞ –∫–æ—Ç–æ—Ä—ã–º –∏–¥–µ—Ç –∑–∞–ø—è—Ç–∞—è, –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∫–æ–Ω–µ—Ü —Å—Ç—Ä–æ–∫–∏/–ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
            r')'  # –ö–æ–Ω–µ—Ü –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            r'([\.\w>]+)?'  # –ì—Ä—É–ø–ø–∞ 3 Translate_politics (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è): –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º —Å–∞–º "–º—É—Å–æ—Ä" - —Ç–æ—á–∫–∏, –±—É–∫–≤—ã(eps), >.
        )

        # –°—Ç—Ä–æ–∫–∞ –¥–ª—è –∑–∞–º–µ–Ω—ã: –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç, –∏—Å–ø–æ–ª—å–∑—É—è –ì—Ä—É–ø–ø—É 2 (—Ü–∏—Ñ—Ä—ã)
        replacement_pattern = r'<<Eqn\2.eps>>'

        # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
        def process_paragraph(para: Paragraph):
            nonlocal changes_made
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ - –∏—â–µ–º —Ö–æ—Ç—è –±—ã –Ω–∞—á–∞–ª–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞
            if '<<Eqn' not in para.text:
                return False

            original_text = para.text
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—É –∫–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
            new_text = pattern.sub(replacement_pattern, original_text)

            if new_text != original_text:
                # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–º–µ–Ω (—Ö–æ—Ç—è –±—ã –ø—Ä–∏–º–µ—Ä–Ω–æ)
                # –≠—Ç–æ –Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ, –Ω–æ –¥–∞–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                num_replacements = len(pattern.findall(original_text))
                changes_made += num_replacements

                # –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞—Ä–∞–≥—Ä–∞—Ñ –∏ –≤—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç
                para.clear()  # –û—á–∏—â–∞–µ—Ç –≤—Å–µ runs –∏ —Ç–µ–∫—Å—Ç
                para.add_run(new_text)  # –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –æ–¥–Ω–∏–º run (–º–æ–∂–µ—Ç —Å–±—Ä–æ—Å–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)

                # Debug Log (–º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
                # print(f"    Debug: Replaced in para. Orig: '{original_text}'. New: '{new_text}'")
                return True
            return False

        # --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ö–æ–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ ---
        # –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
        for para in document.paragraphs: process_paragraph(para)

        # –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º
        for table in document.tables:
            for row in table.rows:
                for cell in row.cells:
                    for para in cell.paragraphs: process_paragraph(para)

        # –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–∞–º (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        for section in document.sections:
            # Headers
            for para in section.header.paragraphs: process_paragraph(para)
            for table in section.header.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for para in cell.paragraphs: process_paragraph(para)
            # Footers
            for para in section.footer.paragraphs: process_paragraph(para)
            for table in section.footer.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for para in cell.paragraphs: process_paragraph(para)
        # --- –ö–æ–Ω–µ—Ü –æ–±—Ö–æ–¥–∞ ---

        if changes_made > 0:
            print(f"  -> –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ V3: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ ~{changes_made} –∏—Å–∫–∞–∂–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –≤ {docx_path.name}")
            document.save(docx_path)  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
        else:
            print(
                f"  -> –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ V3: –ò—Å–∫–∞–∂–µ–Ω–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã (—Ç—Ä–µ–±—É—é—â–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è) –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {docx_path.name}")

        return True

    except FileNotFoundError:
        print(f"  -> –û–®–ò–ë–ö–ê –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω {docx_path}")
        return False
    except Exception as e:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º f-string –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        print(f"  -> –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å {docx_path.name}: {e}")
        print(traceback.format_exc())  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
        return False


def translate_single_document(input_path, output_path, translator, target_lang, source_lang, file_index, total_files,
                              source_root_path, glossary=None):
    """Translates a single document and handles errors. Includes enhanced post-processing for DOCX."""
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Path –æ–±—ä–µ–∫—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è DeepL API –∏ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    input_path_str = str(input_path)
    output_path_str = str(output_path)

    try:
        relative_path_for_display = input_path.relative_to(source_root_path)
    except ValueError:
        relative_path_for_display = input_path
    except Exception as e:
        relative_path_for_display = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—É—Ç–∏: {input_path_str}"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º str
        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ Path –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
    print(f"\n[{file_index}/{total_files}] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {relative_path_for_display}")
    print(f"  –ü–µ—Ä–µ–≤–æ–¥ '{input_path.name}' -> '{output_path.name}'...")
    print(f"     (–Ø–∑—ã–∫–∏: {source_lang} -> {target_lang})")

    post_processing_error_occurred = False  # –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Path –æ–±—ä–µ–∫—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        output_path.parent.mkdir(parents=True, exist_ok=True)

        start_time = time.time()

        # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–ª–æ—Å—Å–∞—Ä–∏—è
        if glossary:
            print(f"     (–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–ª–æ—Å—Å–∞—Ä–∏–π: {glossary.name})")

        # –ü–µ—Ä–µ–¥–∞–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π –≤ —Ñ—É–Ω–∫—Ü–∏—é –ø–µ—Ä–µ–≤–æ–¥–∞, –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω
        translation_kwargs = {
            "input_path": input_path_str,  # DeepL —Ç—Ä–µ–±—É–µ—Ç —Å—Ç—Ä–æ–∫—É
            "output_path": output_path_str,  # DeepL —Ç—Ä–µ–±—É–µ—Ç —Å—Ç—Ä–æ–∫—É
            "target_lang": target_lang,
            "source_lang": source_lang
        }

        if glossary:
            translation_kwargs["glossary"] = glossary

        translator.translate_document_from_filepath(**translation_kwargs)

        end_time = time.time()
        print(f"  -> –£–°–ü–ï–®–ù–û –ø–µ—Ä–µ–≤–µ–¥–µ–Ω –∑–∞ {end_time - start_time:.2f} —Å–µ–∫.")

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        print(f"  -> –ü–∞—É–∑–∞ {PAUSE_BETWEEN_REQUESTS} —Å–µ–∫—É–Ω–¥—ã –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∑–∞–ø—Ä–æ—Å–æ–º...")
        time.sleep(PAUSE_BETWEEN_REQUESTS)

        # --- –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –ü–û–°–¢-–û–ë–†–ê–ë–û–¢–ö–ò ---
        if output_path.suffix.lower() == '.docx':
            print(f"  -> –ó–∞–ø—É—Å–∫ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ V3 –¥–ª—è {output_path.name}...")
            # –ü–µ—Ä–µ–¥–∞–µ–º Path –æ–±—ä–µ–∫—Ç –≤ —Ñ—É–Ω–∫—Ü–∏—é –æ—á–∏—Å—Ç–∫–∏
            cleaning_successful = clean_translated_docx(output_path)
            if not cleaning_successful:
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥
                print(f"  -> –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {output_path.name} –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π.")
                post_processing_error_occurred = True  # –û—Ç–º–µ—á–∞–µ–º –æ—à–∏–±–∫—É –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏
        # --- –ö–û–ù–ï–¶ –ò–ù–¢–ï–ì–†–ê–¶–ò–ò ---

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç—É—Å –∏ –ø—É—Ç–∏. –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏.
        return {
            "status": "success" if not post_processing_error_occurred else "success_with_postprocessing_error",
            "input": input_path_str,
            "output": output_path_str,
            "post_processing_error": post_processing_error_occurred  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É
        }

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ DeepL API –∏ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
    except deepl.DocumentTranslationException as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ DeepL: {e}"
        print(f"  -> –û–®–ò–ë–ö–ê: {error_msg}")
        return {"status": "error", "input": input_path_str, "error": error_msg}
    except deepl.QuotaExceededException:
        error_msg = "–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ DeepL API."
        print(f"  -> –û–®–ò–ë–ö–ê: {error_msg}")
        return {"status": "error", "input": input_path_str, "error": error_msg, "quota_exceeded": True}
    except deepl.TooManyRequestsException:
        error_msg = "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ DeepL API."
        print(f"  -> –û–®–ò–ë–ö–ê: {error_msg}")
        return {"status": "error", "input": input_path_str, "error": error_msg, "rate_limited": True}
    except deepl.ConnectionException as e:
        error_msg = f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ DeepL: {e}"
        print(f"  -> –û–®–ò–ë–ö–ê: {error_msg}")
        return {"status": "error", "input": input_path_str, "error": error_msg}
    except deepl.DeepLException as e:  # –û–±—â–∞—è –æ—à–∏–±–∫–∞ DeepL
        error_msg = f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ DeepL API: {e}"
        print(f"  -> –û–®–ò–ë–ö–ê: {error_msg}")
        return {"status": "error", "input": input_path_str, "error": error_msg}
    except FileNotFoundError:
        # –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –Ω–µ –Ω–∞–π–¥–µ–Ω –ò–°–•–û–î–ù–´–ô —Ñ–∞–π–ª
        error_msg = f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path_str}"
        print(f"  -> –û–®–ò–ë–ö–ê: {error_msg}")
        return {"status": "error", "input": input_path_str, "error": error_msg}
    except PermissionError:
        error_msg = f"–ù–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —á—Ç–µ–Ω–∏–µ/–∑–∞–ø–∏—Å—å —Ñ–∞–π–ª–∞ ({input_path_str} -> {output_path_str})."
        print(f"  -> –û–®–ò–ë–ö–ê: {error_msg}")
        return {"status": "error", "input": input_path_str, "error": error_msg}
    except Exception as e:
        # –ü–µ—Ä–µ—Ö–≤–∞—Ç –¥—Ä—É–≥–∏—Ö –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ (–≤–∫–ª—é—á–∞—è –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ clean_translated_docx)
        error_msg = f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ '{input_path_str}': {e}"
        print(f"  -> –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {error_msg}")
        print(traceback.format_exc())
        return {"status": "error", "input": input_path_str, "output": output_path_str,
                "error": f"{error_msg}\n{traceback.format_exc()}"}


def process_translations(translator, file_paths, source_root_path, target_root_path, source_lang, target_lang,
                         suffix_pattern, glossary=None):
    """Manages the translation process using sequential processing."""
    success_count = 0
    success_with_warnings = 0  # –û—Ç–¥–µ–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ –¥–ª—è —É—Å–ø–µ—Ö–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏
    skipped_suffix_count = 0
    skipped_exists_count = 0
    error_count = 0
    errors_list = []  # –°–ø–∏—Å–æ–∫ –¥–µ—Ç–∞–ª–µ–π –æ—à–∏–±–æ–∫
    total_files = len(file_paths)
    stop_processing = False  # –§–ª–∞–≥ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö API

    actual_suffix = suffix_pattern.format(target_lang_code=target_lang.lower().replace("-", "_"))

    # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º 1 –ø–æ—Ç–æ–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    max_workers = 1
    processing_mode = "–ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–ô"

    print(f"\n–ó–∞–ø—É—Å–∫ {processing_mode} –æ–±—Ä–∞–±–æ—Ç–∫–∏ {total_files} —Ñ–∞–π–ª–æ–≤...")
    print("-" * 30)

    executor = ThreadPoolExecutor(max_workers=max_workers)
    future_to_path_obj = {}  # –•—Ä–∞–Ω–∏–º Path –æ–±—ä–µ–∫—Ç—ã
    files_submitted = 0

    for i, input_path_obj in enumerate(file_paths):  # –ò—Å–ø–æ–ª—å–∑—É–µ–º Path –æ–±—ä–µ–∫—Ç
        if stop_processing:
            print(
                f"\n[{i + 1}/{total_files}] –ü—Ä–æ–ø—É—Å–∫ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞ {input_path_obj.name} –∏–∑-–∑–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏ API.")
            continue

        file_index = i + 1
        try:
            relative_path_for_target = input_path_obj.relative_to(source_root_path)
            output_path_obj = target_root_path / relative_path_for_target.with_name(
                f"{input_path_obj.stem}{actual_suffix}{input_path_obj.suffix}")
        except Exception as e:
            print(
                f"\n[{file_index}/{total_files}] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –ø—É—Ç–∏ –¥–ª—è {input_path_obj.name}: {e}. –ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–π–ª–∞.")
            error_count += 1
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏
            errors_list.append(
                {"status": "error", "file": str(input_path_obj), "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –ø—É—Ç–∏: {e}"})
            continue

        # --- Skip Checks ---
        if input_path_obj.stem.endswith(actual_suffix):
            try:
                display_path = input_path_obj.relative_to(source_root_path)
            except ValueError:
                display_path = input_path_obj.name
            print(f"\n[{file_index}/{total_files}] –ü—Ä–æ–ø—É—Å–∫ (—Ñ–∞–π–ª —É–∂–µ –∏–º–µ–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å '{actual_suffix}'): {display_path}")
            skipped_suffix_count += 1
            continue

        if output_path_obj.exists():
            try:
                display_path = output_path_obj.relative_to(target_root_path)
            except ValueError:
                display_path = output_path_obj.name
            print(f"\n[{file_index}/{total_files}] –ü—Ä–æ–ø—É—Å–∫ (–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç): {display_path}")
            skipped_exists_count += 1
            continue
        # --- End Skip Checks ---

        # Submit the translation task
        future = executor.submit(
            translate_single_document,
            input_path_obj,  # –ü–µ—Ä–µ–¥–∞–µ–º Path
            output_path_obj,  # –ü–µ—Ä–µ–¥–∞–µ–º Path
            translator,
            target_lang,
            source_lang,
            file_index,
            total_files,
            source_root_path,  # Path
            glossary  # –ü–µ—Ä–µ–¥–∞–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π
        )
        future_to_path_obj[future] = input_path_obj  # –•—Ä–∞–Ω–∏–º Path –æ–±—ä–µ–∫—Ç
        files_submitted += 1

    print(f"\n–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {files_submitted} –∑–∞–¥–∞–Ω–∏–π –Ω–∞ –ø–µ—Ä–µ–≤–æ–¥. –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...")

    # --- –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    try:
        for future in as_completed(future_to_path_obj):
            input_path_obj = future_to_path_obj[future]
            input_filename_str = str(input_path_obj)  # –°—Ç—Ä–æ–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤
            try:
                result = future.result()  # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –ø–æ—Ç–æ–∫–∞

                if result['status'] == "success":
                    success_count += 1
                elif result['status'] == "success_with_postprocessing_error":
                    # –£—Å–ø–µ—à–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥, –Ω–æ –ø—Ä–æ–±–ª–µ–º–∞ —Å –æ—á–∏—Å—Ç–∫–æ–π
                    success_with_warnings += 1
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫
                    errors_list.append({
                        "status": "warning",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ç—É—Å warning
                        "file": result.get('input', input_filename_str),
                        "output": result.get('output'),
                        "error": f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {Path(result.get('output', '')).name}"
                    })
                elif result['status'] == "error":
                    # –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–ª–∏ –¥—Ä—É–≥–∞—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
                    error_count += 1
                    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∫–ª—é—á 'file' –µ—Å—Ç—å –≤ —Å–ª–æ–≤–∞—Ä–µ –æ—à–∏–±–∫–∏ –¥–ª—è –æ—Ç—á–µ—Ç–∞
                    if 'file' not in result: result['file'] = result.get('input', input_filename_str)
                    errors_list.append(result)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ API –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                    if result.get("quota_exceeded") or result.get("rate_limited"):
                        if not stop_processing:
                            print("\n*** –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –∫–≤–æ—Ç—ã –∏–ª–∏ –ª–∏–º–∏—Ç–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ DeepL. ***")
                            print("*** –ù–æ–≤—ã–µ –∑–∞–¥–∞–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è. –î–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö. ***")
                        stop_processing = True
                else:
                    # –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å
                    print(
                        f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ '{result.get('status')}' –¥–ª—è —Ñ–∞–π–ª–∞ {input_filename_str}")
                    error_count += 1  # –°—á–∏—Ç–∞–µ–º –∫–∞–∫ –æ—à–∏–±–∫—É
                    errors_list.append({"status": "error", "file": input_filename_str,
                                        "error": f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {result.get('status')}"})


            except Exception as exc:
                # –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑ —Å–∞–º–æ–≥–æ future (—Ä–µ–¥–∫–æ)
                error_count += 1
                error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è —Ñ–∞–π–ª–∞ '{input_filename_str}': {exc}"
                print(f"  -> –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–û–¢–û–ö–ê: {error_msg}")
                print(traceback.format_exc())
                errors_list.append(
                    {"status": "error", "file": input_filename_str, "error": f"{error_msg}\n{traceback.format_exc()}"})
    finally:
        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º –ø—É–ª –ø–æ—Ç–æ–∫–æ–≤
        executor.shutdown(wait=True)

    print("-" * 30)
    print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ —Å—á–µ—Ç—á–∏–∫–∏
    return success_count, success_with_warnings, skipped_suffix_count, skipped_exists_count, error_count, errors_list


# --- –§–£–ù–ö–¶–ò–ò –î–õ–Ø –†–ï–ñ–ò–ú–ê –û–î–ù–û–ì–û –§–ê–ô–õ–ê ---

def handle_single_file(translator):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    print("\n--- –†–µ–∂–∏–º –ø–µ—Ä–µ–≤–æ–¥–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ ---")

    # 1. –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    while True:
        source_str = input("\n–í–≤–µ–¥–∏—Ç–µ –ü–û–õ–ù–´–ô –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞: ").strip().strip('"\'')
        source_path = Path(source_str)
        if source_path.is_file() and source_path.suffix.lower() in SUPPORTED_EXTENSIONS:
            break
        else:
            print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.")
            print(f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(SUPPORTED_EXTENSIONS)}")

    # 2. –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞
    source_lang, target_lang = get_translation_direction()

    # 3 Translate_politics. –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π
    glossary = get_or_create_glossary(translator, source_lang, target_lang)

    # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    target_lang_code_for_suffix = target_lang.lower().replace("-", "_")
    actual_suffix = TRANSLATION_SUFFIX.format(target_lang_code=target_lang_code_for_suffix)
    output_path = source_path.with_name(f"{source_path.stem}{actual_suffix}{source_path.suffix}")

    print("-" * 50)
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {source_path}")
    print(f"–¶–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª: {output_path}")
    print(f"–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {source_lang} -> {target_lang}")
    if glossary:
        print(f"–ì–ª–æ—Å—Å–∞—Ä–∏–π: {glossary.name}")
    print("-" * 50)

    # 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if output_path.exists():
        overwrite = input(f"\n–§–∞–π–ª '{output_path.name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å? (y/n): ").strip().lower()
        if overwrite != 'y':
            print("–ü–µ—Ä–µ–≤–æ–¥ –æ—Ç–º–µ–Ω–µ–Ω.")
            return

    # 6. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
    result = translate_single_document(
        input_path=source_path,
        output_path=output_path,
        translator=translator,
        target_lang=target_lang,
        source_lang=source_lang,
        file_index=1,
        total_files=1,
        source_root_path=source_path.parent,
        glossary=glossary
    )

    # 7. –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("\n" + "=" * 50)
    if result['status'] == "success":
        print("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω!")
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫: {output_path}")
    elif result['status'] == "success_with_postprocessing_error":
        print("‚ö†Ô∏è –§–∞–π–ª –ø–µ—Ä–µ–≤–µ–¥–µ–Ω, –Ω–æ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–µ.")
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫: {output_path}")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Ñ–∞–π–ª–∞.")
        if 'error' in result:
            print(f"–î–µ—Ç–∞–ª–∏: {result['error']}")
    print("=" * 50)


def find_largest_files():
    """–ù–∞–π—Ç–∏ 10 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–∏–º–≤–æ–ª–æ–≤"""
    print("\n--- –ü–æ–∏—Å–∫ 10 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ ---")
    print("\n–í–≤–µ–¥–∏—Ç–µ –ü–û–õ–ù–´–ô –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è –ø–æ–∏—Å–∫–∞")
    print("–ü—Ä–∏–º–µ—Ä –¥–ª—è Mac: /Users/–∏–º—è/Desktop/–ú–æ–∏–î–æ–∫—É–º–µ–Ω—Ç—ã")
    print("–ü—Ä–∏–º–µ—Ä –¥–ª—è Windows: C:\\Users\\–∏–º—è\\Documents\\–ú–æ–∏–î–æ–∫—É–º–µ–Ω—Ç—ã")
    
    while True:
        search_path_str = input("-> ").strip().strip('"\'')
        search_path = Path(search_path_str)
        if search_path.is_dir():
            break
        else:
            print(f"–û—à–∏–±–∫–∞: –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: '{search_path_str}'")
            print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø—É—Ç—å.")
    
    print(f"\n–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤: {search_path}")
    print("–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ñ–∞–π–ª–æ–≤...")
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
    file_data = []
    total_files = 0
    errors = 0
    
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    extensions_to_check = ['.docx', '.pdf', '.txt', '.doc', '.rtf', '.odt']
    
    for ext in extensions_to_check:
        pattern = f"*{ext}"
        for file_path in search_path.rglob(pattern):
            total_files += 1
            try:
                if file_path.is_file() and not file_path.name.startswith('~$'):
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                    file_size = file_path.stat().st_size
                    
                    # –û—Ü–µ–Ω–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–∏–º–≤–æ–ª–æ–≤ –ø–æ —Ç–∏–ø—É —Ñ–∞–π–ª–∞
                    if ext in ['.txt']:
                        # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ - –ø—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω–æ —Ä–∞–∑–º–µ—Ä—É
                        estimated_chars = file_size
                    elif ext in ['.docx', '.doc', '.odt']:
                        # –î–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ Word - –ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                        estimated_chars = int(file_size * 0.7)
                    elif ext in ['.pdf']:
                        # –î–ª—è PDF - –æ—á–µ–Ω—å –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞
                        estimated_chars = int(file_size * 0.4)
                    elif ext in ['.rtf']:
                        # –î–ª—è RTF - —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ç–∫–∏
                        estimated_chars = int(file_size * 0.3)
                    else:
                        estimated_chars = int(file_size * 0.5)
                    
                    file_data.append({
                        'path': file_path,
                        'size': file_size,
                        'chars': estimated_chars,
                        'type': ext
                    })
            except Exception as e:
                errors += 1
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞ {file_path.name}: {e}")
    
    if not file_data:
        print(f"\n–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ.")
        print(f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(extensions_to_check)}")
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–∏–º–≤–æ–ª–æ–≤ (—É–±—ã–≤–∞–Ω–∏–µ)
    file_data.sort(key=lambda x: x['chars'], reverse=True)
    
    # –ë–µ—Ä–µ–º —Ç–æ–ø-10
    top_files = file_data[:10]
    
    print(f"\n{'=' * 80}")
    print(f"–¢–û–ü-10 –°–ê–ú–´–• –ë–û–õ–¨–®–ò–• –§–ê–ô–õ–û–í –ü–û –ö–û–õ–ò–ß–ï–°–¢–í–£ –°–ò–ú–í–û–õ–û–í")
    print(f"{'=' * 80}")
    print(f"–í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(file_data)}")
    if errors > 0:
        print(f"–û—à–∏–±–æ–∫ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {errors}")
    print(f"{'=' * 80}")
    
    for idx, file_info in enumerate(top_files, 1):
        try:
            # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
            rel_path = file_info['path'].relative_to(search_path)
        except ValueError:
            rel_path = file_info['path'].name
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤
        size_mb = file_info['size'] / (1024 * 1024)
        chars_millions = file_info['chars'] / 1_000_000
        
        print(f"\n{idx}. {rel_path}")
        print(f"   –¢–∏–ø: {file_info['type']}")
        print(f"   –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {size_mb:.2f} MB ({file_info['size']:,} –±–∞–π—Ç)")
        print(f"   –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª-–≤–æ —Å–∏–º–≤–æ–ª–æ–≤: {file_info['chars']:,} (~{chars_millions:.2f} –º–ª–Ω)")
        
        # –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
        cost_per_file = chars_millions * 20.00  # ‚Ç¨20 –∑–∞ –º–∏–ª–ª–∏–æ–Ω
        print(f"   –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞: ‚Ç¨{cost_per_file:.2f}")
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ–ø-10
    total_chars = sum(f['chars'] for f in top_files)
    total_size = sum(f['size'] for f in top_files)
    total_cost = (total_chars / 1_000_000) * 20.00
    
    print(f"\n{'=' * 80}")
    print(f"–ò–¢–û–ì–û –î–õ–Ø –¢–û–ü-10 –§–ê–ô–õ–û–í:")
    print(f"  –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size / (1024 * 1024):.2f} MB")
    print(f"  –û–±—â–µ–µ –∫–æ–ª-–≤–æ —Å–∏–º–≤–æ–ª–æ–≤: {total_chars:,} (~{total_chars / 1_000_000:.2f} –º–ª–Ω)")
    print(f"  –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞ –≤—Å–µ—Ö 10 —Ñ–∞–π–ª–æ–≤: ‚Ç¨{total_cost:.2f}")
    print(f"{'=' * 80}")


def handle_folder_translation(translator):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏"""
    print("\n--- –†–µ–∂–∏–º –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–∞–ø–∫–∏ ---")
    print("\n–í–≤–µ–¥–∏—Ç–µ –ü–û–õ–ù–´–ô –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —Ñ–∞–π–ª–∞–º–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
    print("–ü—Ä–∏–º–µ—Ä –¥–ª—è Mac: /Users/–∏–º—è/Desktop/–ú–æ–∏–î–æ–∫—É–º–µ–Ω—Ç—ã")
    print("–ü—Ä–∏–º–µ—Ä –¥–ª—è Windows: C:\\Users\\–∏–º—è\\Documents\\–ú–æ–∏–î–æ–∫—É–º–µ–Ω—Ç—ã")

    while True:
        source_root_str = input("-> ").strip().strip('"\'')
        source_root_path = Path(source_root_str)
        if source_root_path.is_dir():
            break
        else:
            print(f"–û—à–∏–±–∫–∞: –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–∞–ø–∫–æ–π: '{source_root_str}'")
            print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø—É—Ç—å.")

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞
    source_lang, target_lang = get_translation_direction()

    target_lang_code_for_suffix = target_lang.lower().replace("-", "_")
    actual_suffix = TRANSLATION_SUFFIX.format(target_lang_code=target_lang_code_for_suffix)
    target_root_path = source_root_path.with_name(f"{source_root_path.name}{actual_suffix}")

    print("-" * 30)
    print(f"–ò—Å—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞: {source_root_path}")
    print(f"–¶–µ–ª–µ–≤–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {target_root_path}")
    print(f"–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞: {source_lang} -> {target_lang}")
    print(f"–°—É—Ñ—Ñ–∏–∫—Å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {actual_suffix}")
    print(f"–†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏: –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–´–ô (1 —Ñ–∞–π–ª –∑–∞ —Ä–∞–∑)")
    print("-" * 30)

    print(f"\n–ü—Ä–æ–≤–µ—Ä–∫–∞/—Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {target_root_path}")
    try:
        target_root_path.mkdir(parents=True, exist_ok=True)
        print("–ü–∞–ø–∫–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≥–æ—Ç–æ–≤–∞.")
    except PermissionError:
        print(f"–û—à–∏–±–∫–∞: –ù–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ '{target_root_path}'.")
        return
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–∞–ø–∫–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {e}")
        print(traceback.format_exc())
        return

    files_to_translate = find_files_to_translate(source_root_path)

    if not files_to_translate:
        print("\n–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ –∏ –µ–µ –ø–æ–¥–ø–∞–ø–∫–∞—Ö.")
        return

    # –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–∞
    estimated_chars, estimated_cost = estimate_translation_cost(files_to_translate)

    # –ó–∞–ø—Ä–æ—Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
    print(f"\n‚ö†Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ {len(files_to_translate)} —Ñ–∞–π–ª–æ–≤?")
    print(f"   –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ‚Ç¨{estimated_cost:.2f}")
    confirm = input("\n–í–≤–µ–¥–∏—Ç–µ 'y' –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∏–ª–∏ –ª—é–±—É—é –¥—Ä—É–≥—É—é –∫–ª–∞–≤–∏—à—É –¥–ª—è –æ—Ç–º–µ–Ω—ã: ").strip().lower()
    if confirm != 'y':
        print("–ü–µ—Ä–µ–≤–æ–¥ –æ—Ç–º–µ–Ω–µ–Ω.")
        return

    # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
    glossary = get_or_create_glossary(translator, source_lang, target_lang)

    # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    start_usage = translator.get_usage()
    start_chars = start_usage.character.count if start_usage.character.count else 0

    # –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ –æ—á–∏—Å—Ç–∫–∏
    success, warnings, skipped_suffix, skipped_exists, errors, error_details = process_translations(
        translator,
        files_to_translate,
        source_root_path,
        target_root_path,
        source_lang,
        target_lang,
        TRANSLATION_SUFFIX,
        glossary
    )

    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å
    try:
        end_usage = translator.get_usage()
        end_chars = end_usage.character.count if end_usage.character.count else 0
        chars_used = end_chars - start_chars

        if chars_used > 0:
            PRICE_PER_MILLION = 20.00  # EUR
            actual_cost = (chars_used / 1_000_000) * PRICE_PER_MILLION

            print(f"\nüí∞ –†–ï–ê–õ–¨–ù–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨ –ü–ï–†–ï–í–û–î–ê:")
            print(f"  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {chars_used:,}")
            print(f"  ‚Ä¢ –°—Ç–æ–∏–º–æ—Å—Ç—å: ‚Ç¨{actual_cost:.2f}")
            if estimated_cost > 0:
                accuracy = (actual_cost / estimated_cost) * 100
                print(f"  ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏: {accuracy:.1f}%")
    except Exception as e:
        print(f"\n–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏: {e}")

    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("-" * 30)
    print("–ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç:")
    found_count = len(files_to_translate)
    processed_total = success + warnings + skipped_suffix + skipped_exists + errors

    print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ ({', '.join(SUPPORTED_EXTENSIONS)}): {found_count}")
    print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (–≤–∫–ª—é—á–∞—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ): {processed_total}")
    print(f"  –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ –∏ –æ—á–∏—â–µ–Ω–æ (–µ—Å–ª–∏ DOCX): {success}")
    print(f"  –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ, –Ω–æ —Å –æ—à–∏–±–∫–æ–π –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ (DOCX): {warnings}")
    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –∏–º–µ–ª–∏ —Å—É—Ñ—Ñ–∏–∫—Å '{actual_suffix}'): {skipped_suffix}")
    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ (–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç): {skipped_exists}")
    print(f"  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ (–æ—à–∏–±–∫–∏ API/–¥–æ—Å—Ç—É–ø–∞/—Ñ–∞–π–ª–∞): {errors}")

    # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏
    if errors > 0 or warnings > 0:
        print("\n–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π:")
        error_details.sort(key=lambda x: 0 if x.get('status') == 'error' else 1)

        for i, err_info in enumerate(error_details):
            input_file_path_str = str(err_info.get('file', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–∞–π–ª'))
            try:
                file_display_name = Path(input_file_path_str).relative_to(source_root_path)
            except (ValueError, TypeError):
                file_display_name = input_file_path_str

            status = err_info.get('status', 'error')
            prefix = "–û—à–∏–±–∫–∞"
            if status == "warning":
                prefix = "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ"

            error_message_full = str(err_info.get('error', '–ù–µ—Ç –¥–µ—Ç–∞–ª–µ–π'))
            error_message_short = error_message_full.splitlines()[0]

            print(f"  {i + 1}. –§–∞–π–ª: {file_display_name}")
            print(f"     {prefix}: {error_message_short}")

    print(f"\n–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {target_root_path}")
    print("-" * 30)


# --- Main Execution ---

if __name__ == "__main__":
    start_total_time = time.time()

    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    args = parse_arguments()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
    check_api_key_placeholder()
    translator = initialize_translator(DEEPL_API_KEY)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—â–µ–Ω –ª–∏ —Å–∫—Ä–∏–ø—Ç –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ
    if args.no_interactive and args.input:
        # === –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ñ–ò–ú ===
        input_path = Path(args.input)

        if not input_path.exists():
            print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
            sys.exit(1)

        if not input_path.suffix.lower() in SUPPORTED_EXTENSIONS:
            print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {input_path.suffix}")
            print(f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(SUPPORTED_EXTENSIONS)}")
            sys.exit(1)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
        if args.output:
            output_path = Path(args.output)
        else:
            target_suffix = f"_to_{args.target.lower().replace('-', '_')}"
            output_path = input_path.with_name(f"{input_path.stem}{target_suffix}{input_path.suffix}")

        print(f"\n=== –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ñ–ò–ú ===")
        print(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_path}")
        print(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_path}")
        print(f"–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {args.source} -> {args.target}")

        # –ü–æ–ª—É—á–∞–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π –µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ
        glossary = get_or_create_glossary(translator, args.source, args.target)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
        result = translate_single_document(
            input_path=input_path,
            output_path=output_path,
            translator=translator,
            target_lang=args.target,
            source_lang=args.source,
            file_index=1,
            total_files=1,
            source_root_path=input_path.parent,
            glossary=glossary
        )

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
        if result['status'] == 'success':
            print("‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω!")
            sys.exit(0)
        elif result['status'] == 'success_with_postprocessing_error':
            print("‚ö†Ô∏è –§–∞–π–ª –ø–µ—Ä–µ–≤–µ–¥–µ–Ω, –Ω–æ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–µ.")
            sys.exit(0)  # –í—Å–µ —Ä–∞–≤–Ω–æ —Å—á–∏—Ç–∞–µ–º —É—Å–ø–µ—Ö–æ–º –¥–ª—è workflow
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Ñ–∞–π–ª–∞.")
            if 'error' in result:
                print(f"–î–µ—Ç–∞–ª–∏: {result['error']}")
            sys.exit(1)

    else:
        # === –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –†–ï–ñ–ò–ú ===
        # –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
        while True:
            print("\n" + "=" * 50)
            print("DeepL Document Translator - –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º")
            print("=" * 50)
            print("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
            print("  1. –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª")
            print("  2. –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ)")
            print("  3 Translate_politics. –ù–∞–π—Ç–∏ 10 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤")
            print("  4. –í—ã—Ö–æ–¥")

            mode_choice = input("\n–í–∞—à –≤—ã–±–æ—Ä (1, 2, 3 Translate_politics –∏–ª–∏ 4): ").strip()

            if mode_choice == '1':
                handle_single_file(translator)
            elif mode_choice == '2':
                handle_folder_translation(translator)
            elif mode_choice == '3 Translate_politics':
                find_largest_files()
            elif mode_choice == '4':
                print("\n–í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã.")
                break
            else:
                print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ 1, 2, 3 Translate_politics –∏–ª–∏ 4.")

        end_total_time = time.time()
        print(f"\n–û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {end_total_time - start_total_time:.2f} —Å–µ–∫—É–Ω–¥.")