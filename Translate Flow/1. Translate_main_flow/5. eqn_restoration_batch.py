#!/usr/bin/env python3
"""
EQN RESTORATION BATCH - FIXED VERSION V2
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤

–ù–û–í–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:
1. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ (–±–µ–∑ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏—Ö << –∏–ª–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö >>)
2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
3. –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö
4. –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
"""

import sys
from pathlib import Path
import re
from datetime import datetime
import json

try:
    from docx import Document
except ImportError:
    print("–û—à–∏–±–∫–∞: –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ python-docx.")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx")
    sys.exit(1)


class PlaceholderRestorer:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤"""
    
    def __init__(self):
        self.stats = {
            'placeholders_replaced': 0,
            'placeholders_found_in_translation': 0,
            'placeholders_found_in_original': 0,
            'damaged_placeholders_fixed': 0,
            'damaged_placeholders_details': []
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        self.pattern_placeholder = re.compile(r'<<Eqn\d+(?:\.eps)?>>(?:,)?', re.IGNORECASE)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        # –ù–∞—Ö–æ–¥–∏—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã: <EqnXXX.eps>>, <<EqnXXX.eps>, <EqnXXX.eps>, EqnXXX.eps>>
        self.pattern_damaged = re.compile(
            r'(?:<{1,2})?Eqn\d+(?:\.eps)?(?:>{1,2})?(?:,)?', 
            re.IGNORECASE
        )
        
    def find_and_fix_damaged_placeholders(self, text, para_info=""):
        """
        –ù–∞—Ö–æ–¥–∏—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –≤ —Ç–µ–∫—Å—Ç–µ
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π_—Ç–µ–∫—Å—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π, —Å–ø–∏—Å–æ–∫_–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π)
        """
        fixed_count = 0
        fixes = []
        
        def fix_placeholder(match):
            nonlocal fixed_count
            original = match.group(0)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞
            num_match = re.search(r'Eqn(\d+)', original, re.IGNORECASE)
            if not num_match:
                return original
                
            num = num_match.group(1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            if not original.startswith('<<') or not original.endswith('>>'):
                # –°—Ç—Ä–æ–∏–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                if '.eps' in original.lower():
                    correct = f'<<Eqn{num}.eps>>'
                else:
                    correct = f'<<Eqn{num}>>'
                    
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞
                if original.endswith(','):
                    correct += ','
                    
                if original != correct:
                    fixed_count += 1
                    fixes.append({
                        'original': original,
                        'fixed': correct,
                        'location': para_info
                    })
                    return correct
                    
            return original
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
        fixed_text = self.pattern_damaged.sub(fix_placeholder, text)
        
        return fixed_text, fixed_count, fixes
    
    def check_document_for_damaged_placeholders(self, doc_path):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        """
        problems = []
        
        try:
            document = Document(doc_path)
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å {doc_path.name}: {e}")
            return problems
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        for i, para in enumerate(document.paragraphs):
            if para.text:
                # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
                all_matches = self.pattern_damaged.findall(para.text)
                correct_matches = self.pattern_placeholder.findall(para.text)
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–∞–∑–Ω–∏—Ü–∞, –∑–Ω–∞—á–∏—Ç –µ—Å—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ
                if len(all_matches) > len(correct_matches):
                    for match in all_matches:
                        if not self.pattern_placeholder.match(match):
                            problems.append({
                                'para_index': i,
                                'location': 'paragraph',
                                'text': para.text[:100] + '...' if len(para.text) > 100 else para.text,
                                'damaged': match
                            })
                    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∞–±–ª–∏—Ü—ã
        for t_idx, table in enumerate(document.tables):
            for r_idx, row in enumerate(table.rows):
                for c_idx, cell in enumerate(row.cells):
                    for p_idx, para in enumerate(cell.paragraphs):
                        if para.text:
                            all_matches = self.pattern_damaged.findall(para.text)
                            correct_matches = self.pattern_placeholder.findall(para.text)
                            
                            if len(all_matches) > len(correct_matches):
                                for match in all_matches:
                                    if not self.pattern_placeholder.match(match):
                                        problems.append({
                                            'table': t_idx,
                                            'row': r_idx,
                                            'cell': c_idx,
                                            'para_in_cell': p_idx,
                                            'location': 'table',
                                            'text': para.text[:100] + '...' if len(para.text) > 100 else para.text,
                                            'damaged': match
                                        })
        
        return problems
        
    def extract_placeholders_list(self, doc_path):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –ø–æ—Ä—è–¥–∫–µ –ø–æ—è–≤–ª–µ–Ω–∏—è
        """
        placeholders = []
        
        try:
            document = Document(doc_path)
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å {doc_path.name}: {e}")
            return []
            
        # –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        for para in document.paragraphs:
            if para.text:
                matches = self.pattern_placeholder.findall(para.text)
                placeholders.extend(matches)
                
        # –¢–∞–±–ª–∏—Ü—ã
        for table in document.tables:
            for row in table.rows:
                for cell in row.cells:
                    for para in cell.paragraphs:
                        if para.text:
                            matches = self.pattern_placeholder.findall(para.text)
                            placeholders.extend(matches)
                            
        # –ö–æ–ª–æ–Ω—Ç–∏—Ç—É–ª—ã
        for section in document.sections:
            for para in section.header.paragraphs:
                if para.text:
                    matches = self.pattern_placeholder.findall(para.text)
                    placeholders.extend(matches)
            for para in section.footer.paragraphs:
                if para.text:
                    matches = self.pattern_placeholder.findall(para.text)
                    placeholders.extend(matches)
                    
        return placeholders
        
    def process_document(self, doc_path, output_path=None, original_doc_path=None, fix_damaged=True, force_mode=False):
        """
        –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –õ–û–ì–ò–ö–ò –∏–∑ ai_studio_code.py - EQN RESTORATION BATCH VERSION 10.2
        """
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é –ª–æ–≥–∏–∫—É –∏–∑ process_document_binary
        original_text = self._get_all_text_from_docx(original_doc_path)
        if original_text is None: 
            return False, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª."

        pattern_strict = re.compile(r'<<Eqn\d+(?:\.eps)?>>', re.IGNORECASE)
        original_placeholders = pattern_strict.findall(original_text)

        translation_text = self._get_all_text_from_docx(doc_path)
        if translation_text is None: 
            return False, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –ø–µ—Ä–µ–≤–æ–¥–∞."

        pattern_robust = re.compile(r'[<\\>,\s]*?Eqn\d+(?:\.eps)?[<\\>,\s]*', re.IGNORECASE)
        translation_placeholders_found = pattern_robust.findall(translation_text)

        try:
            if not original_placeholders:
                if not translation_placeholders_found:
                    # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Å–æ–∑–¥–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –ø–∞–ø–∫–∏ –ø–µ—Ä–µ–¥ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    import shutil
                    shutil.copy(doc_path, output_path)
                    return True, "–ü–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Ñ–∞–π–ª —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω."
                else:
                    print(f"         - –í–ù–ò–ú–ê–ù–ò–ï: –í –æ—Ä–∏–≥–∏–Ω–∞–ª–µ –Ω–µ—Ç –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤. –£–¥–∞–ª–µ–Ω–∏–µ {len(translation_placeholders_found)} –ª–∏—à–Ω–∏—Ö –∏–∑ –ø–µ—Ä–µ–≤–æ–¥–∞...")
                    with open(doc_path, 'rb') as f:
                        binary_content = f.read()
                    for placeholder_to_remove in translation_placeholders_found:
                        binary_content = binary_content.replace(placeholder_to_remove.encode('utf-8'), b'')
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(output_path, 'wb') as f:
                        f.write(binary_content)
                    return True, f"–£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ {len(translation_placeholders_found)} –ª–∏—à–Ω–∏—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤."

            if len(original_placeholders) != len(translation_placeholders_found):
                message = f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {len(original_placeholders)} –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ vs {len(translation_placeholders_found)} –≤ –ø–µ—Ä–µ–≤–æ–¥–µ."
                if not force_mode:
                    return False, f"{message} –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞."
                else:
                    print(f"         ‚ö†Ô∏è  {message}")
                    print("         - –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –†–ï–ñ–ò–ú. –õ–∏—à–Ω–∏–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã.")
                    translation_placeholders_found = translation_placeholders_found[:len(original_placeholders)]

            with open(doc_path, 'rb') as f:
                binary_content = f.read()

            for i, placeholder_to_replace in enumerate(translation_placeholders_found):
                binary_content = binary_content.replace(
                    placeholder_to_replace.encode('utf-8', 'replace'),
                    original_placeholders[i].encode('utf-8', 'replace'),
                    1
                )

            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'wb') as f:
                f.write(binary_content)
            
            return True, f"–£—Å–ø–µ—à–Ω–æ –∑–∞–º–µ–Ω–µ–Ω–æ: {len(original_placeholders)} –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤."

        except Exception as e:
            import traceback
            traceback.print_exc()
            return False, f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}"
            
    def _get_all_text_from_docx(self, doc_path):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –í–ï–°–¨ —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ê–ù–ê–õ–ò–ó–ê."""
        try:
            document = Document(doc_path)
            full_text = []
            for para in document.paragraphs: 
                full_text.append(para.text)
            for table in document.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for para in cell.paragraphs: 
                            full_text.append(para.text)
            for section in document.sections:
                for para in section.header.paragraphs: 
                    full_text.append(para.text)
                for para in section.footer.paragraphs: 
                    full_text.append(para.text)
            return "\n".join(full_text)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {doc_path.name}: {e}")
            return None
            
    def analyze_and_report(self, translation_path, original_path):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –≤—ã–≤–æ–¥–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç
        """
        print("\n" + "="*70)
        print("–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í")
        print("="*70)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
        print(f"\nüìã –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞: {translation_path.name}")
        problems = self.check_document_for_damaged_placeholders(translation_path)
        
        if problems:
            print(f"\n‚ö†Ô∏è  –ù–ê–ô–î–ï–ù–û –ü–û–í–†–ï–ñ–î–ï–ù–ù–´–• –ü–õ–ï–ô–°–•–û–õ–î–ï–†–û–í: {len(problems)}")
            print("\n–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏:")
            for i, prob in enumerate(problems, 1):
                print(f"\n{i}. {prob['damaged']}")
                print(f"   –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {prob['location']}")
                if 'para_index' in prob:
                    print(f"   –ü–∞—Ä–∞–≥—Ä–∞—Ñ: {prob['para_index']}")
                print(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: {prob['text']}")
        else:
            print("‚úÖ –í—Å–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
        trans_placeholders = self.extract_placeholders_list(translation_path)
        orig_placeholders = self.extract_placeholders_list(original_path)
        
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤:")
        print(f"   ‚Ä¢ –í –ø–µ—Ä–µ–≤–æ–¥–µ: {len(trans_placeholders)} (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã—Ö)")
        print(f"   ‚Ä¢ –í –æ—Ä–∏–≥–∏–Ω–∞–ª–µ: {len(orig_placeholders)}")
        
        if len(trans_placeholders) != len(orig_placeholders):
            print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç!")
            diff = abs(len(trans_placeholders) - len(orig_placeholders))
            if len(trans_placeholders) > len(orig_placeholders):
                print(f"   –í –ø–µ—Ä–µ–≤–æ–¥–µ –Ω–∞ {diff} –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –±–æ–ª—å—à–µ")
            else:
                print(f"   –í –æ—Ä–∏–≥–∏–Ω–∞–ª–µ –Ω–∞ {diff} –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –±–æ–ª—å—à–µ")


def find_translation_original_pairs(translations_root, originals_root, translation_suffix='_to_en_us'):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –ø–∞—Ä—ã –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –ø–∞–ø–æ–∫
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - translations_root: –∫–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
    - originals_root: –∫–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞–º–∏
    - translation_suffix: —Å—É—Ñ—Ñ–∏–∫—Å –≤ –∏–º–µ–Ω–∞—Ö –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π: (–ø—É—Ç—å_–∫_–ø–µ—Ä–µ–≤–æ–¥—É, –ø—É—Ç—å_–∫_–æ—Ä–∏–≥–∏–Ω–∞–ª—É)
    """
    pairs = []
    not_found = []
    
    # –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞
    possible_suffixes = ['_translated_en-us', '_translated_en_us', '_to_en_us', '_to_en-us', '_en', '_EN']
    
    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –Ω–∞—Ö–æ–¥–∏–º –≤—Å–µ .docx —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    for translation_file in translations_root.rglob("*.docx"):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if translation_file.name.startswith("~$"):
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if "_restored" in translation_file.name:
            continue
            
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç –∫–æ—Ä–Ω—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        try:
            relative_path = translation_file.relative_to(translations_root)
        except ValueError:
            continue
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ (—É–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å –ø–µ—Ä–µ–≤–æ–¥–∞)
        original_name = translation_file.name
        for suffix in possible_suffixes:
            if suffix in translation_file.stem:
                original_stem = translation_file.stem.replace(suffix, '')
                original_name = original_stem + translation_file.suffix
                break
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è
        translation_parent = relative_path.parent
        
        # –£–±–∏—Ä–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å—ã –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–∑ –ø—É—Ç–∏ –ø–∞–ø–æ–∫
        original_parent_parts = []
        for part in translation_parent.parts:
            part_cleaned = part
            for suffix in ['_to_en_us', '_en', '_EN', '_translated']:
                if part.endswith(suffix):
                    part_cleaned = part[:-len(suffix)]
                    break
            original_parent_parts.append(part_cleaned)
        
        # –°—Ç—Ä–æ–∏–º –ø—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—É
        if original_parent_parts:
            original_path = originals_root / Path(*original_parent_parts) / original_name
        else:
            original_path = originals_root / original_name
        
        if original_path.exists():
            pairs.append((translation_file, original_path))
        else:
            not_found.append({
                'translation': translation_file,
                'expected_original': original_path
            })
            
    return pairs, not_found


def process_multiple_files(pairs, restorer, output_root, translations_root, dry_run=False, force_mode=False):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - pairs: —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–ø–µ—Ä–µ–≤–æ–¥, –æ—Ä–∏–≥–∏–Ω–∞–ª)
    - restorer: —ç–∫–∑–µ–º–ø–ª—è—Ä PlaceholderRestorer
    - output_root: –∫–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - translations_root: –∫–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ (–¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π)
    - dry_run: –µ—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ
    - force_mode: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    """
    results = {
        'success': [],
        'failed': [],
        'skipped': [],
        'processed_without_placeholders': [],
        'damaged_fixed': [],
        'stats': {
            'total_files': len(pairs),
            'total_placeholders_replaced': 0,
            'total_damaged_fixed': 0,
            'files_without_placeholders': 0
        }
    }
    
    if dry_run:
        print("\nüîç –†–ï–ñ–ò–ú –ü–†–ï–î–ü–†–û–°–ú–û–¢–†–ê (–∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã)")
    
    total = len(pairs)
    for i, (translation, original) in enumerate(pairs, 1):
        print(f"\n[{i}/{total}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {translation.name}")
        print(f"         –û—Ä–∏–≥–∏–Ω–∞–ª: {original.name}")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫
        try:
            relative_path = translation.relative_to(translations_root)
            output_path = output_root / relative_path
        except ValueError:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            output_path = output_root / translation.name
            
        if output_path.exists():
            print("         ‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω: –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            results['skipped'].append({
                'file': translation,
                'reason': '–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç'
            })
            continue
        
        if dry_run:
            # –í —Ä–µ–∂–∏–º–µ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ç–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
            problems = restorer.check_document_for_damaged_placeholders(translation)
            trans_placeholders = restorer.extract_placeholders_list(translation)
            orig_placeholders = restorer.extract_placeholders_list(original)
            
            if problems:
                print(f"         ‚ö†Ô∏è  –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤: {len(problems)}")
            if trans_placeholders and orig_placeholders:
                print(f"         üìä –ü–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤: –ø–µ—Ä–µ–≤–æ–¥={len(trans_placeholders)}, –æ—Ä–∏–≥–∏–Ω–∞–ª={len(orig_placeholders)}")
                if len(trans_placeholders) != len(orig_placeholders):
                    print("         ‚ö†Ô∏è  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç!")
            results['success'].append({
                'file': translation,
                'output': output_path,
                'message': f"–ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(trans_placeholders) if trans_placeholders else 0} –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤"
            })
        else:
            # –†–µ–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            try:
                success, message = restorer.process_document(
                    translation,
                    output_path=output_path,
                    original_doc_path=original,
                    fix_damaged=True,
                    force_mode=force_mode
                )
                
                if success:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    if "–±–µ–∑ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤" in message:
                        results['processed_without_placeholders'].append({
                            'file': translation,
                            'output': output_path,
                            'message': message
                        })
                        results['stats']['files_without_placeholders'] += 1
                    else:
                        results['success'].append({
                            'file': translation,
                            'output': output_path,
                            'message': message
                        })
                        
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                        if "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö" in message:
                            results['stats']['total_damaged_fixed'] += restorer.stats['damaged_placeholders_fixed']
                            if restorer.stats['damaged_placeholders_fixed'] > 0:
                                results['damaged_fixed'].append({
                                    'file': translation,
                                    'count': restorer.stats['damaged_placeholders_fixed'],
                                    'details': restorer.stats['damaged_placeholders_details']
                                })
                        results['stats']['total_placeholders_replaced'] += restorer.stats['placeholders_replaced']
                else:
                    results['failed'].append({
                        'file': translation,
                        'error': message
                    })
                    
            except Exception as e:
                results['failed'].append({
                    'file': translation,
                    'error': str(e)
                })
                
    return results


def generate_report(results, not_found, output_file=None):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"eqn_restoration_report_{timestamp}.txt"
    
    report_lines = []
    report_lines.append("="*80)
    report_lines.append("–û–¢–ß–ï–¢ –û –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ò –ü–õ–ï–ô–°–•–û–õ–î–ï–†–û–í –£–†–ê–í–ù–ï–ù–ò–ô")
    report_lines.append("="*80)
    report_lines.append(f"–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("")
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    report_lines.append("–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    report_lines.append("-"*40)
    report_lines.append(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {results['stats']['total_files']}")
    report_lines.append(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞–º–∏: {len(results['success'])}")
    report_lines.append(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤: {results['stats']['total_damaged_fixed']}")
    report_lines.append(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–µ–∑ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤: {len(results.get('processed_without_placeholders', []))}")
    report_lines.append(f"–° –æ—à–∏–±–∫–∞–º–∏: {len(results['failed'])}")
    report_lines.append(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: {len(results['skipped'])}")
    report_lines.append(f"–§–∞–π–ª–æ–≤ –±–µ–∑ –ø–∞—Ä—ã: {len(not_found)}")
    report_lines.append(f"–í—Å–µ–≥–æ –∑–∞–º–µ–Ω–µ–Ω–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤: {results['stats']['total_placeholders_replaced']}")
    report_lines.append("")
    
    # –§–∞–π–ª—ã —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–º–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞–º–∏
    if results.get('damaged_fixed'):
        report_lines.append("\n–§–ê–ô–õ–´ –° –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ú–ò –ü–û–í–†–ï–ñ–î–ï–ù–ù–´–ú–ò –ü–õ–ï–ô–°–•–û–õ–î–ï–†–ê–ú–ò:")
        report_lines.append("-"*40)
        for item in results['damaged_fixed']:
            report_lines.append(f"üîß {item['file'].name}")
            report_lines.append(f"   –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {item['count']} –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤")
            for detail in item['details'][:3]:
                report_lines.append(f"   ‚Ä¢ {detail['original']} ‚Üí {detail['fixed']}")
            if len(item['details']) > 3:
                report_lines.append(f"   ... –∏ –µ—â–µ {len(item['details']) - 3}")
            report_lines.append("")
    
    # –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    if results['success']:
        report_lines.append("\n–£–°–ü–ï–®–ù–û –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–ï –§–ê–ô–õ–´:")
        report_lines.append("-"*40)
        for item in results['success']:
            report_lines.append(f"‚úÖ {item['file'].name}")
            report_lines.append(f"   ‚Üí {item['output'].name}")
            report_lines.append(f"   {item['message']}")
            report_lines.append("")
    
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏...
    # [–ö–æ–¥ –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –æ—Å—Ç–∞–µ—Ç—Å—è —Ç–µ–º –∂–µ]
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report_text = "\n".join(report_lines)
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        print(f"\nüìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    except Exception as e:
        print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç: {e}")
    
    # –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
    print("\n" + "="*70)
    print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*70)
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results['success'])}")
    if results['stats']['total_damaged_fixed'] > 0:
        print(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤: {results['stats']['total_damaged_fixed']}")
    print(f"üìä –í—Å–µ–≥–æ –∑–∞–º–µ–Ω–µ–Ω–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤: {results['stats']['total_placeholders_replaced']}")
    if results['failed']:
        print(f"‚ùå –° –æ—à–∏–±–∫–∞–º–∏: {len(results['failed'])}")
    if not_found:
        print(f"‚ùì –ë–µ–∑ –ø–∞—Ä—ã: {len(not_found)}")
    
    return output_file


def process_single_file(restorer):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    print("\n1. –ü—É—Ç—å –∫ –ü–ï–†–ï–í–ï–î–ï–ù–ù–û–ú–£ —Ñ–∞–π–ª—É:")
    file_path = input("   ‚Üí ").strip().strip('"\'')
    file_path = Path(file_path)
    
    if not file_path.exists() or not file_path.is_file():
        print(f"\n‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
        
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
    print("\n2. –ü—É—Ç—å –∫ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ú–£ —Ñ–∞–π–ª—É:")
    original_path = input("   ‚Üí ").strip().strip('"\'')
    original_path = Path(original_path)
    
    if not original_path.exists() or not original_path.is_file():
        print(f"\n‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {original_path}")
        return
    
    # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    restorer.analyze_and_report(file_path, original_path)
    
    # –°–ø—Ä–∞—à–∏–≤–∞–µ–º, –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ª–∏
    print("\n" + "="*70)
    choice = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É? (y/n): ").strip().lower()
    if choice != 'y':
        print("–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞.")
        return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    print("\n" + "="*70)
    print("–û–ë–†–ê–ë–û–¢–ö–ê")
    print("="*70)
    
    print("\n‚è≥ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
    
    success, message = restorer.process_document(
        file_path,
        original_doc_path=original_path,
        fix_damaged=True
    )
    
    if success:
        print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ!")
        print(f"üìä {message}")
        output_path = file_path.parent / f"{file_path.stem}_restored{file_path.suffix}"
        print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        if restorer.stats['damaged_placeholders_fixed'] > 0:
            print(f"\nüìù –î–µ—Ç–∞–ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤:")
            for fix in restorer.stats['damaged_placeholders_details'][:5]:
                print(f"   ‚Ä¢ {fix['original']} ‚Üí {fix['fixed']} ({fix['location']})")
            if len(restorer.stats['damaged_placeholders_details']) > 5:
                print(f"   ... –∏ –µ—â–µ {len(restorer.stats['damaged_placeholders_details']) - 5}")
    else:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {message}")


def process_folders(restorer):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–æ–∫ —Å —Ñ–∞–π–ª–∞–º–∏"""
    print("\n" + "="*70)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –ü–ê–ü–û–ö")
    print("="*70)
    
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–∞–ø–∫—É —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
    print("\n1. –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ü–ï–†–ï–í–ï–î–ï–ù–ù–´–ú–ò —Ñ–∞–π–ª–∞–º–∏:")
    print("   (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –¥–æ–ª–∂–Ω–∞ –≤–∫–ª—é—á–∞—Ç—å —Å—É—Ñ—Ñ–∏–∫—Å—ã _en, _EN, _to_en_us –∏ —Ç.–ø.)")
    translations_path = input("   ‚Üí ").strip().strip('"\'')
    translations_root = Path(translations_path)
    
    if not translations_root.exists() or not translations_root.is_dir():
        print(f"\n‚ùå –û—à–∏–±–∫–∞: –ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {translations_root}")
        return
    
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–∞–ø–∫—É —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞–º–∏
    print("\n2. –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ú–ò —Ñ–∞–π–ª–∞–º–∏:")
    originals_path = input("   ‚Üí ").strip().strip('"\'')
    originals_root = Path(originals_path)
    
    if not originals_root.exists() or not originals_root.is_dir():
        print(f"\n‚ùå –û—à–∏–±–∫–∞: –ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {originals_root}")
        return
    
    print(f"\nüìÅ –ü–∞–ø–∫–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏: {translations_root}")
    print(f"üìÅ –ü–∞–ø–∫–∞ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞–º–∏: {originals_root}")
    
    # –ü–æ–∏—Å–∫ –ø–∞—Ä —Ñ–∞–π–ª–æ–≤
    print("\nüîç –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –º–µ–∂–¥—É –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞–º–∏...")
    pairs, not_found = find_translation_original_pairs(translations_root, originals_root)
    
    if not pairs:
        print("\n‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –ø–∞—Ä—ã —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
        if not_found:
            print(f"   –ù–∞–π–¥–µ–Ω–æ {len(not_found)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –±–µ–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤.")
            print("\n   –ü–µ—Ä–≤—ã–µ 5 –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö:")
            for item in not_found[:5]:
                print(f"   ‚Ä¢ {item['translation'].name} ‚Üí –∏—Å–∫–∞–ª–∏: {item['expected_original']}")
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print(f"   ‚Ä¢ –ü–∞—Ä —Ñ–∞–π–ª–æ–≤: {len(pairs)}")
    print(f"   ‚Ä¢ –ü–µ—Ä–µ–≤–æ–¥–æ–≤ –±–µ–∑ –ø–∞—Ä—ã: {len(not_found)}")
    
    # –û–ø—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print("\n" + "="*70)
    print("–û–ü–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò")
    print("="*70)
    print("1. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º)")
    print("2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º)")
    print("3. –†–µ–∂–∏–º –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ)")
    print("4. –û—Ç–º–µ–Ω–∞")
    
    choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é (1-4): ").strip()
    
    if choice == '4':
        print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞.")
        return
    
    # –°–æ–∑–¥–∞–µ–º –∏–º—è –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_folder_name = translations_root.name + "_restored"
    output_root = translations_root.parent / output_folder_name
    
    print(f"\nüìÅ –ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {output_root}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º—ã
    force_mode = (choice == '2')
    dry_run = (choice == '3')
    
    if force_mode:
        print("‚ö†Ô∏è  –í—ã–±—Ä–∞–Ω –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –†–ï–ñ–ò–ú - –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    if choice in ['1', '2']:
        try:
            output_root.mkdir(parents=True, exist_ok=True)
            print(f"‚úÖ –ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≥–æ—Ç–æ–≤–∞")
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    print("\n" + "="*70)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –§–ê–ô–õ–û–í")
    print("="*70)
    
    results = process_multiple_files(pairs, restorer, output_root, translations_root, dry_run=dry_run, force_mode=force_mode)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    if not dry_run:
        generate_report(results, not_found)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –≤—ã–±–æ—Ä–æ–º —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã"""
    print("\n" + "="*70)
    print("      EQN RESTORATION BATCH - FIXED VERSION V2")
    print("  –° –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤")
    print("="*70)
    print("\n–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏:")
    print("‚Ä¢ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, <Eqn023.eps>>)")
    print("‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤")
    print("‚Ä¢ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞")
    print("‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ —Ü–µ–ª—ã—Ö –ø–∞–ø–æ–∫")
    print("‚Ä¢ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –≤—Å–µ—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö")
    
    print("\n–ü—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã:")
    print("‚Ä¢ 1-–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –≤ –ø–µ—Ä–µ–≤–æ–¥–µ ‚Üí 1-–π –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞")
    print("‚Ä¢ 2-–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –≤ –ø–µ—Ä–µ–≤–æ–¥–µ ‚Üí 2-–π –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞")
    print("‚Ä¢ –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ...")
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
    restorer = PlaceholderRestorer()
    
    # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞
    print("\n" + "="*70)
    print("–í–´–ë–ï–†–ò–¢–ï –†–ï–ñ–ò–ú –†–ê–ë–û–¢–´")
    print("="*70)
    print("1. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –û–î–ò–ù —Ñ–∞–π–ª")
    print("2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ü–ê–ü–ö–£ —Å —Ñ–∞–π–ª–∞–º–∏")
    print("3. –í—ã—Ö–æ–¥")
    
    choice = input("\n–í–∞—à –≤—ã–±–æ—Ä (1-3): ").strip()
    
    if choice == '1':
        process_single_file(restorer)
    elif choice == '2':
        process_folders(restorer)
    elif choice == '3':
        print("\n–í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã.")
    else:
        print("\n‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä!")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n\n–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()